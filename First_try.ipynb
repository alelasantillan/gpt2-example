{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alelasantillan/gpt2-example/blob/master/First_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYHFcFgwcOI5",
        "colab_type": "text"
      },
      "source": [
        "### Analyticsvidhya - GPT-2 implementation\n",
        "https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4704APEcUWU",
        "colab_type": "code",
        "outputId": "3d32f69d-2309-4615-f523-59fc8884595e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 188 (delta 0), reused 0 (delta 0), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (188/188), 4.36 MiB | 5.90 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCUNfL5cj-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"gpt-2\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xpitsXA3VhP",
        "colab_type": "code",
        "outputId": "a0ffda53-c03d-4186-deb9-20e138a781d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt-2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYcWr4iodjgT",
        "colab_type": "code",
        "outputId": "7f22ae3c-ab6b-4573-bc8d-111f6998a1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['requirements.txt',\n",
              " 'download_model.py',\n",
              " 'src',\n",
              " 'LICENSE',\n",
              " 'Dockerfile.gpu',\n",
              " '.gitattributes',\n",
              " '.git',\n",
              " 'CONTRIBUTORS.md',\n",
              " '.gitignore',\n",
              " 'DEVELOPERS.md',\n",
              " 'README.md',\n",
              " 'Dockerfile.cpu']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr9l_lDIduYU",
        "colab_type": "code",
        "outputId": "fa88960c-67a1-47a0-a096-469107e6368f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.12.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.12.0 in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.16.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (0.15.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_eyp-zE21kh",
        "colab_type": "code",
        "outputId": "ecfa8335-a1f6-4de9-ca27-b53c7c5ee046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "#vi que en el ejemplo de https://github.com/avivajpeyi/investigating-gpt2/blob/master/GPT2_Investigation.ipynb\n",
        "#primero bbajaba el modelo y despues instalaba los requerimientos\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/6e/48cf0cffb7bf0bb58746bff99ed2d1a2769a32c4d74c06f988eb3e554f86/fire-0.2.0.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 7.0MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/7d/8e/95d6c85f2080a8be09a12a669474122b2e3921fccd3922baf1\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.0 regex-2017.4.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGB9oR_r5H0x",
        "colab_type": "code",
        "outputId": "a62a4fc5-ca18-49c4-be35-179539286ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'download_model.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnTScLcI5NnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOO8iN-m51Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir(\"gpt-2\")\n",
        "os.chdir('src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuSHkgLT7eSY",
        "colab_type": "code",
        "outputId": "945e7044-6947-43ae-eace-6235cd313cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encoder.py',\n",
              " 'sample.py',\n",
              " 'interactive_conditional_samples.py',\n",
              " '__pycache__',\n",
              " 'model.py',\n",
              " 'generate_unconditional_samples.py']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSo3NN0-7UFj",
        "colab_type": "code",
        "outputId": "4d6f6fd6-322b-437f-bb51-a0f035e04353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt-2/src'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esNtLY7o-KFO",
        "colab_type": "code",
        "outputId": "93646791-0884-4ede-b0e3-d726f8fbdda6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip3 install regex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 40.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built regex\n",
            "Installing collected packages: regex\n",
            "Successfully installed regex-2019.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34DuPmAf535D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "file_dir = os.path.dirname(\"/content/gpt-2/src\")\n",
        "sys.path.append(file_dir)\n",
        "import model, sample, encoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn5mY7Q2-Ti5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interact_model(\n",
        "    model_name,\n",
        "    seed,\n",
        "    nsamples,\n",
        "    batch_size,\n",
        "    length,\n",
        "    temperature,\n",
        "    top_k,\n",
        "    models_dir\n",
        "):\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        while True:\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "            while not raw_text:\n",
        "                print('Prompt should not be empty!')\n",
        "                raw_text = input(\"Model prompt >>> \")\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "            generated = 0\n",
        "            for _ in range(nsamples // batch_size):\n",
        "                out = sess.run(output, feed_dict={\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "                })[:, len(context_tokens):]\n",
        "                for i in range(batch_size):\n",
        "                    generated += 1\n",
        "                    text = enc.decode(out[i])\n",
        "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "                    print(text)\n",
        "            print(\"=\" * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5sfbYGzBScs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir(\"../\")\n",
        "#os.chdir('src')\n",
        "#os.getcwd()\n",
        "#os.listdir()\n",
        "#os.mkdir('models')\n",
        "#os.chdir('models')\n",
        "#os.mkdir('345M')\n",
        "os.chdir('345M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKTCjF63ALHw",
        "colab_type": "code",
        "outputId": "1a89389b-030e-4c61-f464-bf346fbc75e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "interact_model(\n",
        "    '345M',\n",
        "    None,\n",
        "    1,\n",
        "    1,\n",
        "    300,\n",
        "    1,\n",
        "    0,\n",
        "    '/content/gpt-2/models'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7d832fd16da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m'/content/gpt-2/models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-35-9bbb37a09480>\u001b[0m in \u001b[0;36minteract_model\u001b[0;34m(model_name, seed, nsamples, batch_size, length, temperature, top_k, models_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnsamples\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hparams.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gpt-2/src/encoder.py\u001b[0m in \u001b[0;36mget_encoder\u001b[0;34m(model_name, models_dir)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoder.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab.bpe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gpt-2/models/345M/encoder.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMQuVb1XU84u",
        "colab_type": "text"
      },
      "source": [
        "# \"2nd try\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u66QSfz0TuRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7503e1a0-e3b9-47d3-e5b3-d89d466bf8e4"
      },
      "source": [
        "import os\n",
        "#os.chdir(\"../\")\n",
        "#os.chdir('src')\n",
        "#os.chdir('content')\n",
        "#os.getcwd()\n",
        "os.listdir()\n",
        "#os.mkdir('models')\n",
        "#os.chdir('models')\n",
        "#os.mkdir('345M')\n",
        "#os.chdir('345M')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'gpt-2', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96DOdqv1VHbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bddc5b4-c760-4466-dc37-c40fb00af6e4"
      },
      "source": [
        "# testing GPU connection\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found; Go to Runtime > Change Runtime Type > Harware Accelerator > GPU')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3LO38yVOe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4db9081e-7868-4e67-b100-15f0d0338787"
      },
      "source": [
        "# Clone repo \n",
        "! git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrVMD3m5VTEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Move to gpt-2 repo\n",
        "import os\n",
        "os.chdir('gpt-2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8a2yh3OVXs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2a6f28af-1084-4b83-cd53-e11c38224c9c"
      },
      "source": [
        "\n",
        "# download model and install dependencies\n",
        "!python download_model.py 345M\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 594kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 33.2Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 786kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:28, 50.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 4.34Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 32.1Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 34.0Mit/s]                                                       \n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx3wjdWfTbzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae577879-acbb-4789-d567-babe0be52aa4"
      },
      "source": [
        "#en https://github.com/avivajpeyi/investigating-gpt2/blob/master/GPT2_Investigation.ipynb\n",
        "#bajaba esto para unconditional generation\n",
        "!python3 src/generate_unconditional_samples.py --model_name='345M' --nsamples=3 --top_k=10\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 14:01:59.724915 139774885799808 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:53: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-07-31 14:01:59.726980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-31 14:01:59.729845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.730277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:01:59.730568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:01:59.731951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:01:59.733242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:01:59.733617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:01:59.735383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:01:59.736721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:01:59.740307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:01:59.740446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.740935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.741298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:01:59.746622: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-31 14:01:59.746871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25eb480 executing computations on platform Host. Devices:\n",
            "2019-07-31 14:01:59.746908: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-31 14:01:59.808255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.808898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f39180 executing computations on platform CUDA. Devices:\n",
            "2019-07-31 14:01:59.808933: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-31 14:01:59.809293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.809718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:01:59.809807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:01:59.809848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:01:59.809903: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:01:59.809947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:01:59.809985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:01:59.810021: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:01:59.810058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:01:59.810180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.810666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.811018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:01:59.811079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:01:59.812294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-31 14:01:59.812329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-31 14:01:59.812349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-31 14:01:59.812701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.813175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:01:59.813570: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-31 14:01:59.813624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0731 14:01:59.814561 139774885799808 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:55: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0731 14:01:59.822944 139774885799808 deprecation_wrapper.py:119] From /content/gpt-2/src/sample.py:33: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0731 14:01:59.823121 139774885799808 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0731 14:01:59.824258 139774885799808 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0731 14:02:04.227250 139774885799808 deprecation.py:323] From /content/gpt-2/src/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0731 14:02:04.247298 139774885799808 deprecation.py:323] From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0731 14:02:04.250010 139774885799808 deprecation.py:323] From /content/gpt-2/src/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0731 14:02:09.549047 139774885799808 deprecation_wrapper.py:119] From src/generate_unconditional_samples.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0731 14:02:09.849539 139774885799808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-07-31 14:02:17.747165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "If the U.S. is to succeed in its fight against terrorism, it must continue to pursue and prosecute those responsible for acts of violence and terrorist attacks against American citizens.\"\n",
            "\n",
            "The State Department has issued a new policy on how the administration would seek to respond to future attacks by foreign nationals. Under the new policy, officials could seek to take the lead in arresting and detaining the people who would do the attacking. This would mean the administration was prepared to take the lead in bringing to justice those who would carry out attacks that would be carried out in the name of terrorism.\n",
            "\n",
            "\"If we have learned anything over the last year is that there needs to be a clear strategy, we're going to have to do that,\" State Department spokesperson Heather Nauert, said when the policy was released on May 27.\n",
            "\n",
            "Nauert did not specify what this strategy would be, but she added it would include the following: \"A comprehensive strategy to identify and counter violent extremism. A strategy to address threats to the homeland and international peace and security.\"\n",
            "\n",
            "The policy was first announced by Secretary of State John Kerry in March and was expected to go into effect by the end of the year. It was also reported that the policy was being reviewed by Secretary of Homeland Security Jeh Johnson and Secretary of State John Kerry.\n",
            "\n",
            "The policy is not the first time the U.S. has considered ways to counter violent extremist ideology, however. The U.S. government is currently developing a plan to combat violent extremist ideology and has also proposed a \"Countering Violent Extremism\" initiative under the State Department's Countering Terrorism Center.\n",
            "\n",
            "The U.S. also has conducted a study on the issue and has released a series of reports, including a 2012 report that called \"Violent Extremism: What's the Big Problem?\" The report, titled \"Violent Extremism,\" was published at the request of then-Sen. Chuck Schumer (D-NY), a Democrat who was then running for president in 2012, and is a member of the Foreign Relations Committee.<|endoftext|>The new generation of smart cars will be equipped with sensors and cameras to keep tabs on their surroundings and the cars themselves as well, with a big change coming with the launch of the next-gen Mercedes-Benz S-Class sedan next summer.\n",
            "\n",
            "The company has announced plans for a new version of its S-Class sedan, which will feature a new camera system and more advanced sensors, including a camera mounted at the front.\n",
            "\n",
            "This system will enable drivers to see how the vehicles are performing on the road in real time and even give them insight into what their driving style might be.\n",
            "\n",
            "The company also claims that it's going to introduce a new, more efficient version of the S-Class sedan, which will also have a camera system.\n",
            "\n",
            "The new system will allow drivers to see how the vehicles are performing on the road in real time and even give them insight into what their driving style might be\n",
            "\n",
            "This will be the first time in history that the car maker has offered a car with a new camera system as standard equipment for drivers – and it will allow the driver to be more aware and see the vehicles they're driving through the vehicle's rearview mirror.\n",
            "\n",
            "The new system will be fitted in all models of the S-Class from the S-Class S to the S-Class E, with the first model, currently the new E-Class, to get it.\n",
            "\n",
            "The camera system will be installed on the rear view mirror in the S-Class E and will be available on all variants of the vehicle.\n",
            "\n",
            "The carmaker has also introduced a new version of the S-Class sedan – which is set to debut in 2018 – which will feature a wider range of options\n",
            "\n",
            "It will get more advanced technologies including a rear-mounted camera, an electric assist, a rearview camera that will be available for those with a driver's licence in Germany, a camera on the roof of the vehicle and a rear-mounted radar, which will be available for the S-Class E.\n",
            "\n",
            "The new camera system is said to have an advanced range and will provide a wider range of vision in the rearview mirror.\n",
            "\n",
            "The driver will be able to see how well the vehicle is doing at different speeds on the pavement as well as the speed at which the car is travelling.\n",
            "\n",
            "The S-Class E will be the last vehicle in its class to get the cameras.\n",
            "\n",
            "The company will also introduce a new version of its S-Class, which will get more advanced features including more fuel efficient and quieter engines, and a range of new technology such as a new powertrain management system that will allow drivers to adjust fuel consumption when there is insufficient acceleration on the road.\n",
            "\n",
            "The new S-Class will also have a powertrain management system, which will help the driver control the acceleration and braking of the engine in the event that they are not able to keep up in terms of speed.\n",
            "\n",
            "The new system\n",
            "======================================== SAMPLE 2 ========================================\n",
            "The United States has spent billions of dollars on drone attacks against al-Qaeda and its allies, and the Obama administration is now looking into using drones to target suspected terrorists abroad. But the CIA has spent a lot more on drone strikes in Pakistan, Yemen and Somalia, and has reportedly begun considering using the weapons in other countries.\n",
            "\n",
            "According to the New York Times, U.S. military officials are considering using drones to attack militants in Yemen and Somalia.\n",
            "\n",
            "The Pentagon is considering using the weapons to help \"take out terrorists in the Middle East and Africa that have a long history of using these weapons against U.S. military, government and civilian targets,\" according to the paper.\n",
            "\n",
            "U.S. officials told the Times they believe drone strikes against al-Qaeda affiliates will be the \"new normal\" for the military as they work to eliminate them. The military is also developing a special \"deterrence and retaliation\" program against terror groups in the region.\n",
            "\n",
            "The Pentagon is currently developing its own counterterrorism capabilities. The military is also working on developing \"counterintelligence capabilities\" for drone strikes to counter \"threats of terrorism\" from al-Qaeda, according to the Times.\n",
            "\n",
            "In September, Obama announced that he planned to expand drone strikes against al-Qaeda and its affiliates to Pakistan, the region's deadliest nation with an estimated 10,000 to 15,000 terrorist attacks a year, according to the Times.\n",
            "\n",
            "In addition to targeting al-Qaeda affiliates, the White House has also said it would expand the use of drones to attack suspected terrorists in Afghanistan.\n",
            "\n",
            "The Pentagon has said it has not yet determined what kind of weapon the new weapons could be used with or against, but officials told the Times that they would be used against the Taliban.\n",
            "\n",
            "The Times reports that the Pentagon's decision on whether to use the drones against terrorist groups in Yemen has been a long time coming. The Pentagon has previously said it had to decide what weapons to buy and when the weapons could be used.<|endoftext|>The New Yorker is one of many publications reporting that the FBI is using social-media accounts in order to monitor activists in a way that violates their freedom of expression.\n",
            "\n",
            "This is the latest twist in an increasingly complex and contentious controversy over how to regulate and control the use of social media, and the extent to which it is being used to target political opponents and dissidents.\n",
            "\n",
            "Last month, The New Yorker published a lengthy story based on a series of internal interviews with FBI agents and social media specialists, in which the magazine's senior editors and reporters, including the editor-in-chief, wrote about what they saw as the government's growing use of social media in a way that is inconsistent with the First Amendment and free press. It became a national scandal after the story was published in full.\n",
            "\n",
            "\"There is an increasing number of people who want us to think that it's OK to use our social-media accounts to attack and harass others,\" a senior official who was a social-media specialist told the magazine's reporter. \"We see people who are using the social-media accounts to make a point. We've seen people using them to try to intimidate others. I can say to them that you can be a good, thoughtful person, and I don't care if you're a good writer, journalist or a journalist with good feelings, but I'm going to be able to shut this up if you don't.\"\n",
            "\n",
            "This story is being covered very much like an ongoing controversy surrounding the use of Twitter and Facebook. As The New Republic reports, this \"is the latest twist in an increasingly complex and contentious controversy over how to regulate and control the use of social media, and the extent to which it is being used to target political opponents and dissidents.\"\n",
            "\n",
            "The article was not written out of the blue; it had been written over a week earlier by the magazine's senior editor for public affairs, David Remnick, in a piece titled, \"Twitter and the New Yorker's First Amendment,\" which he published in January. In it, Remnick detailed how Twitter allows its users to use \"to share, tweet, or otherwise share content about the writer, the writer's writing, the work, or the work of others on Twitter.\" The article also detailed how Twitter and Facebook allow people to use their \"real names\" to post messages, such as messages that read \"I am a writer, and I'm not a troll.\" (Remnick wrote that he had never used Facebook to do such an activity, and said that this was a mistake.)\n",
            "\n",
            "The New Yorker's editors and reporters also wrote, \"In our view, the use of the social-media service is a direct violation of the First Amendment and the Constitution's guarantee that 'free speech' shall never be infringed.\" (That last point is crucial. As The Intercept's Glenn Greenwald has pointed out, social-media sites are not free speech sites; they are not open-government websites, and they do not have a First Amendment right to monitor\n",
            "======================================== SAMPLE 3 ========================================\n",
            "The new president and CEO of the New York Mets, Terry Collins, has been named the new owner of the club.\n",
            "\n",
            "Collins will take over as the club's general manager in the summer of 2014 and oversee all aspects of the Mets. The Mets will remain a part of the New York City Baseball League, and will not be in the NLCS for the first time in six seasons.\n",
            "\n",
            "The Mets will also play at Citizens Bank Park, home of the Mets.\n",
            "\n",
            "Collins was the New York Yankees' general manager when they won the World Series in 2008. He was also the Mets' general manager from 2003-07 before he stepped down last season. He was named manager of the Yankees in 2009.\n",
            "\n",
            "Collins also served as Mets manager for one year from 2010-13 and as a scout for the team's minor league affiliates from 2010-11 until he was fired following the 2010 season. He had been in charge of the New York Mets since 2004 and led the Mets to two NL East championship berths between 2003 and 2007, and to four postseason berths between 2008 and 2010.\n",
            "\n",
            "The Mets have been under team ownership the past two years, with ownership groups consisting of former owners Frank and David Wells.<|endoftext|>This is how I make a sandwich.\n",
            "\n",
            "I love my sandwiches. I've been a sandwich person since my first sandwich, and I've never stopped. I think I've made about a half dozen sandwich recipes this season, and this is by far the best. The bread is moist and delicious, and it's just perfect for a sandwich or sandwich wrap. If you have no experience with meat in a sandwich, you can skip to Part 2.\n",
            "\n",
            "For a sandwich that's just meat and veggies, I like to serve this over some of the best smoked salmon I've ever had! I love that the meat is marinated in a sauce that's a blend of red onion, garlic powder, and salt, so it has a nice crunch and flavor. It has a nice, slightly spicy kick that makes this a great pairing with a glass of wine, especially one with a lot of black cavendish, and that's not something you can get on a regular basis here, but that's what I love. It's a great, unique, and unique sandwich to pair with any wine.\n",
            "\n",
            "If you like to add some extra flavor to your sandwich, I highly recommend you to order a half bottle of the \"Saucy Porter\" to add to your sandwich. It's an extremely light beer and I love that it has a nice, light, smooth mouthfeel that's not too thick or sweet. The addition of a bit of a sweet sour note to this is an awesome addition to this sandwich.\n",
            "\n",
            "The meat and veggies are marinated for about 10 days, and I make the sandwich as a whole-grain sandwich in a large skillet, which is perfect for a sandwich. I think the whole grain version tastes just as good as the \"whole grain\" version, and you can add some more vegetables to the meat for an extra boost of flavor.\n",
            "\n",
            "The bread is a perfect, moist, and chewy, and the meat and greens are all perfectly tender. The sandwich is super easy to make – it requires a bit of time, but you won't go wrong. This sandwich is one of those recipes that everyone should try!\n",
            "\n",
            "I hope you love this recipe as much as I love making it! If you have any questions, comments, or questions you would like to have addressed directly to me, please feel free to contact me on Facebook or Twitter! Happy baking, everyone!<|endoftext|>When it comes to a good story, I always try to make them as believable as possible. I try to keep the plot moving at a reasonable pace while still keeping the main character interesting (or at least not annoying). I want my characters to feel like they are making choices and making decisions that have a major effect on the world of the game. I don't care about how much exposition you provide for the plot; I only care that the characters have some sort of impact on the storyline.\n",
            "\n",
            "One of the biggest things that comes out of writing a story is that we need time to get to know your characters and what their backgrounds are. A lot of stories can be really simple with just a simple premise and an interesting plot. A lot of stories are really complex and require time and careful thought to get to the point. This means that it's important to give your characters and their actions enough time to develop and grow over a long period of time, or it's just going to fall apart. I like to keep my story moving as much as possible with my characters so I'm going to be focusing on that for the next post, so keep reading!\n",
            "\n",
            "In this part I'm going to focus on how I structure the narrative of a story, and then go on to talk about the different aspects of story structure I have in mind for my games.\n",
            "\n",
            "I'm going to start by going\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwKagZAOVxNQ",
        "colab_type": "text"
      },
      "source": [
        "# For conditional generation\n",
        "Generates text sampels conditional on some user input\n",
        "\n",
        "Notes on flags:\n",
        "The code comes with a few flags available, with a default value:\n",
        "\n",
        "* seed = None || a random value is generated unless specified. give a specific integer value if you want to reproduce same results in the future.\n",
        "* nsamples = 1 || specify the number of samples you want to print\n",
        "* length = None || number of tokens (words) to print on each sample.\n",
        "* batch_size = 1 || how many inputs you want to process simultaneously. doesn't seem to affect the results.\n",
        "* temperature = 1 || scales logits before sampling prior to softmax.\n",
        "* top_k = 0 || truncates the set of logits considered to those with the highest values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Different usecases:\n",
        "\n",
        "1. Text completion\n",
        "\n",
        "2. Question answering\n",
        "\n",
        "3. Summarisation\n",
        "\n",
        "4. Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4xW5H5XWISv",
        "colab_type": "text"
      },
      "source": [
        "# 1. Text Completion\n",
        "\n",
        "Feed in some random text and see what the AI generates from that!\n",
        "\n",
        "**Example usage**\n",
        " !python3 src/interactive_conditional_samples.py --nsamples=2 --top_k=40 --temperature=.80 --model_name='345M'\n",
        "\n",
        "Model prompt >>> \"Our solar system consists of the inner and outer planets, separated by an asteroid belt. It has \"\n",
        "\n",
        "Model prompt >>> \"The 10 best foods are: 1. Peanut butter jelly sandwiches 2. Marshmallows 3. Broccoli 4.\"\n",
        "\n",
        "Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGxAOuaQV755",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0464e06-09e5-4a45-b7fb-b47c74b44cd0"
      },
      "source": [
        "\n",
        "!python3 src/interactive_conditional_samples.py --nsamples=2 --top_k=40 --temperature=.80 --model_name='345M'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 14:08:53.934029 140006535784320 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:56: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-07-31 14:08:53.935909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-31 14:08:53.938920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:53.939333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:08:53.939644: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:08:53.940913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:08:53.942088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:08:53.942454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:08:53.944067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:08:53.945389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:08:53.948933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:08:53.949122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:53.949638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:53.949996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:08:53.955325: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-31 14:08:53.955605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1baf480 executing computations on platform Host. Devices:\n",
            "2019-07-31 14:08:53.955642: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-31 14:08:54.019289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.019858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x743b180 executing computations on platform CUDA. Devices:\n",
            "2019-07-31 14:08:54.019897: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-31 14:08:54.020173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.020565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:08:54.020642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:08:54.020684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:08:54.020728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:08:54.020765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:08:54.020800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:08:54.020841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:08:54.020878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:08:54.021000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.021455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.021823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:08:54.021918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:08:54.023110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-31 14:08:54.023150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-31 14:08:54.023176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-31 14:08:54.023496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.023961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:08:54.024335: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-31 14:08:54.024389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0731 14:08:54.025297 140006535784320 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:57: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 14:08:54.027907 140006535784320 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:59: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0731 14:08:54.028153 140006535784320 deprecation_wrapper.py:119] From /content/gpt-2/src/sample.py:33: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0731 14:08:54.028315 140006535784320 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0731 14:08:59.943559 140006535784320 deprecation.py:323] From /content/gpt-2/src/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0731 14:08:59.962339 140006535784320 deprecation.py:323] From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0731 14:08:59.965023 140006535784320 deprecation.py:323] From /content/gpt-2/src/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0731 14:09:05.229276 140006535784320 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:67: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0731 14:09:05.533571 140006535784320 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> En la ciudad de La Plata un triste suceso ha tenido lugar\n",
            "2019-07-31 14:09:37.110462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            ", son lo que puedes muy buena muy gente, puedes piedras como lugar. En una tarde de la piedra, no se puede no de que te una ciencia de los piedras.\n",
            "\n",
            "\"Oh, no, I don't like it,\" said the woman. \"I don't want to eat a dog's flesh, and you're making me feel so ridiculous!\" She said it in a low, low, low voice, and then she looked at the man. \"Would it be better for you to eat a dog's flesh?\"\n",
            "\n",
            "\"It would be much better for me.\"\n",
            "\n",
            "\"I see, and I understand,\" said the woman. \"It is like looking into one's own heart, and seeing that one is happy.\"\n",
            "\n",
            "\"I don't understand you,\" said the man. \"You don't understand anything. You should understand that I don't like the taste of dogs. I've eaten dog's meat before; but I didn't like it so much. Why should I give that up?\"\n",
            "\n",
            "\"When you have eaten dog's flesh,\" said the woman, \"you should feel a strange feeling of enjoyment. The sensation is like the first time you feel it, like eating meat and knowing that you have tasted something wonderful. That is the sensation of taste. The taste of dog's flesh, however, is better.\"\n",
            "\n",
            "\"I don't understand you at all,\" said the man. \"I feel that I should like to taste it, and I believe you. I think that you must like to taste dog's flesh. I don't know exactly how to do that, but I can't sit down and eat a dog's flesh anymore.\"\n",
            "\n",
            "\"I don't really know how you have to eat dog's flesh,\" said the woman. \"It seems quite hard for me. I hate it a little bit.\"\n",
            "\n",
            "The man tried to talk something out to her, until finally he said:\n",
            "\n",
            "\"I believe that you have lost your humanity. I don't want to eat dog's flesh, and I don't know how you feel about eating dog's flesh. Is there a dog's meat for me to eat? No, I don't think so. I'll give you a dog's flesh just once, if you won't eat dog's flesh anymore, and then I'll eat dog's flesh again.\"\n",
            "\n",
            "\"I don't want dog's\n",
            "======================================== SAMPLE 2 ========================================\n",
            " para el plata. Estoy con el cuentad de la Plata ha sido que la ciudad de la Plata, y la triste suceso, es una entradas de la ciudad de la Plata.\n",
            "\n",
            "The Spanish general had already reached the camp, and the Spanish officers were already there. The general looked at the officers and said:\n",
            "\n",
            "\"I cannot go to the camp without permission. For this reason I have not had the pleasure of seeing you from the camp. I have been on the march for months. I have not yet crossed the river, and I have not yet seen what is below me in this field. If I were to cross, I should not be able to get to La Plata, but it is clear that, under the enemy's fire and my loss of a portion of my horse, I could not cross. I shall see you in two weeks, and I will take a horse and go through the camp. No one will know which of the two roads the two roads lead to, but as long as you do not attempt to cross the river we are certain to find you there at once. I shall give you permission to cross, but if you refuse I shall not allow you the liberty of crossing the river. If you refuse, they will kill you. I have also, to your great astonishment, heard the noise which is so frequent at this time of the year. You cannot find it in all the mountains of Spain; only in this one, La Plata. It is the greatest noise that is heard in the desert, the most terrible. I do not know whether these Indians know the valley or not. If they did it was because they had heard so many things in those days.\"\n",
            "\n",
            "These words of the general, with the following words, were communicated to the chief of the Indians, and they gave him full authority to go to the Spanish General.\n",
            "\n",
            "There was no doubt that the Spanish general understood what was said, and he was now in a condition of danger. He looked towards the camp, thinking that he would find somewhere to stay; he thought he might be able to get to the camp and then escape, but he could not get there. He then looked again to the camp, and saw all the Indians, and the horses, who were very good, very swift, very well maintained, and he saw many of them. So he was afraid of the situation of the town. He also\n",
            "================================================================================\n",
            "Model prompt >>> In the city of La Plata, Argentina, a sad event has taking place:\n",
            "======================================== SAMPLE 1 ========================================\n",
            " a 40-year-old woman known as \"La Noche\" has passed away due to an accidental overdose.\n",
            "\n",
            "The story of this woman is one of those that will leave you in shock and despair. La Noche had a son, a daughter, two sisters and a brother, and her family moved to Buenos Aires, Argentina when he was just 3 years old, in 1996. She went to live with her mother in the city of Chilpancingo, and her family grew up in a relatively wealthy family with friends and family. In 2001, her son was born.\n",
            "\n",
            "In 2002, however, the La Noche family's fortune started to collapse. In particular, their bank collapsed, and a lawsuit was filed by the family claiming that their savings had been stolen. Since then, the family had been forced to pay thousands in legal fees, and many people around the world started to question their true motivations and intentions.\n",
            "\n",
            "La Noche was extremely protective about her son, but her husband and family refused to pay any attention to how they were managing their money, and instead went on an extravagant spending spree.\n",
            "\n",
            "The family also stopped eating properly, and used their money to start a car collection business. In fact, they had been on the road for 20 years. As a result, La Noche was diagnosed with Type 1 diabetes, and had been using a dietician's diet to help control her diabetes. This, along with over $100,000 in personal expenses meant that she needed to be hospitalized and on a diabetic shock treatment.\n",
            "\n",
            "The government of Argentina tried to help save her life, but to no avail. La Noche's illness had become so severe that she was in dire need of urgent attention. Doctors in Los Angeles, Argentina, told the family of the dire situation they were in, and wanted to start a fund to help raise funds to pay for the hospital costs and all of her personal expenses.\n",
            "\n",
            "Eventually, in 2004, the family's money stopped being donated and was instead spent by the family members. The family members were desperate to get their money back, and they wanted the financial assistance that could help cover their expenses in order to pay for their medical bills and other personal expenses. It did not take long for the fund to grow to around $100,000, and the family were shocked to learn that they had failed to give their funds to the family when they had asked so much.\n",
            "\n",
            "The family decided that it was time to make a donation, and they\n",
            "======================================== SAMPLE 2 ========================================\n",
            " an Argentinian man has been sentenced to death for murdering his wife by firing a fatal bullet just minutes before they were to marry.\n",
            "\n",
            "Argentina's Supreme Court upheld the sentence of 27-year-old Luis Felipe Garcia on Tuesday, ruling that he did not act in self-defense, but simply shot his wife because \"she was not acting in a suitable way.\"\n",
            "\n",
            "On the day they were to marry, Felipe allegedly began berating his wife by saying he would \"take her out to the city\" and then fired the fatal bullet into her head.\n",
            "\n",
            "\"After the firing, the couple was left alone to sleep,\" the judge said, according to The Local.\n",
            "\n",
            "In the wake of the incident, a petition on Change.org was launched calling for Felipe's immediate release, with over 50,000 people signing it.\n",
            "\n",
            "\"Felipe has been a victim of a serious crime, and his freedom is under threat,\" the petition read. \"Argentina's judiciary cannot allow Felipe's death sentence to be carried out due to his own poor mental state, and that is why we, the people of Argentina, will not stand idly by while he is sentenced to death.\"\n",
            "\n",
            "The verdict prompted widespread rage on social media sites, with many people saying they would have been willing to leave their fellow citizens behind if they were convicted of such a crime.\n",
            "\n",
            "The country's justice system is notorious for its lack of fairness, with the majority of the country's cases being either thrown out after only minor or even second-degree murder convictions, or with the accused being acquitted of any crime at all.\n",
            "\n",
            "The case has led to a nationwide outcry in Argentina, with the country's President Mauricio Macri expressing his \"shock\" and warning the system would not stand idly by in such a scenario.\n",
            "\n",
            "\"It's the same as in the USA when you're accused of a crime, and you're acquitted. It's a terrible situation,\" he said. \"We will not allow this.\"\n",
            "\n",
            "At least 24 people have been killed in Argentina in the last year, while more than 1,000 others have been injured in police shootings or at protests.\n",
            "\n",
            "Follow Jack Montgomery on Twitter: @JackBMontgomery<|endoftext|>This is a guest post by Ryan D. Smith, the founder of the New Zealand Institute of Criminology.\n",
            "\n",
            "This article was originally published in the July/August 2013 issue of the Crime Prevention magazine.\n",
            "\n",
            "There are two\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5652, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 72, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 90, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 87, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1619, in __exit__\n",
            "    close_thread.join(30.0)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1060, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRoaw1M3YSTY",
        "colab_type": "text"
      },
      "source": [
        "# 2. Question-Answering\n",
        "Feed in a passage, and then some question/answer pairs (Q: blah blah? A: Blah blah.), and token A:. The AI will answer the previous ''Q:''\n",
        "\n",
        "Note, for a single word answer (i.e.: Yes/No, city), set flag length=1\n",
        "\n",
        "**Example usage**\n",
        "\n",
        "> !python3 src/interactive_conditional_samples.py --nsamples=10 --top_k=40 --temperature=.80 --length=1 --model_name='345M'\n",
        ">\n",
        ">Model Prompt >>>\n",
        ">\n",
        ">The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer\n",
        "Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in\n",
        "Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried\n",
        "the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started\n",
        "ahead of the 1936 Summer Olympics.\n",
        "After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was\n",
        "following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing\n",
        "ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of\n",
        "Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event.\n",
        ">\n",
        ">Q: What was the length of the race?\n",
        ">\n",
        ">A: 137,000 km\n",
        ">\n",
        ">Q: Was it larger than previous ones?\n",
        ">\n",
        ">A: No\n",
        ">\n",
        ">Q: Where did the race begin?\n",
        ">\n",
        ">A: Olympia, Greece\n",
        ">\n",
        ">Q: Where did they go after?\n",
        ">\n",
        ">A: Athens\n",
        ">\n",
        ">Q: How many days was the race?\n",
        ">\n",
        ">A: seven\n",
        ">\n",
        ">Q: Did they visit any notable landmarks?\n",
        ">\n",
        ">A: Panathinaiko Stadium\n",
        ">\n",
        ">Q: And did they climb any mountains?\n",
        ">\n",
        ">A:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-QbBLXwYR4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82a85dd9-0f8c-4e98-be7d-00b01932f14c"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=10 --top_k=40 --temperature=.80 --length=1 --model_name='345M'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 14:26:23.855015 140543752943488 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:56: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-07-31 14:26:23.856928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-31 14:26:23.859796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.860230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:26:23.860504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:26:23.861834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:26:23.863083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:26:23.863477: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:26:23.865131: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:26:23.866439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:26:23.869814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:26:23.870000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.870489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.870846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:26:23.876379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-31 14:26:23.876635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a67480 executing computations on platform Host. Devices:\n",
            "2019-07-31 14:26:23.876674: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-31 14:26:23.936998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.937568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x72f3180 executing computations on platform CUDA. Devices:\n",
            "2019-07-31 14:26:23.937606: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-31 14:26:23.937846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.938246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:26:23.938322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:26:23.938364: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:26:23.938408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:26:23.938456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:26:23.938499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:26:23.938534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:26:23.938571: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:26:23.938691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.939140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.939529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:26:23.939608: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:26:23.941698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-31 14:26:23.941745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-31 14:26:23.941774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-31 14:26:23.942394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.942964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:26:23.943372: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-31 14:26:23.943436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0731 14:26:23.944316 140543752943488 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:57: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 14:26:23.946815 140543752943488 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:59: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0731 14:26:23.947050 140543752943488 deprecation_wrapper.py:119] From /content/gpt-2/src/sample.py:33: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0731 14:26:23.947220 140543752943488 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0731 14:26:29.879463 140543752943488 deprecation.py:323] From /content/gpt-2/src/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0731 14:26:29.898181 140543752943488 deprecation.py:323] From /content/gpt-2/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0731 14:26:29.900813 140543752943488 deprecation.py:323] From /content/gpt-2/src/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started ahead of the 1936 Summer Olympics. After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event.  Q: What was the length of the race?  A: \n",
            "W0731 14:26:35.120707 140543752943488 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:67: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0731 14:26:35.413716 140543752943488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> 2019-07-31 14:26:43.064577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            " \n",
            "======================================== SAMPLE 2 ========================================\n",
            "Â\n",
            "======================================== SAMPLE 3 ========================================\n",
            " The\n",
            "======================================== SAMPLE 4 ========================================\n",
            " \n",
            "======================================== SAMPLE 5 ========================================\n",
            " \n",
            "======================================== SAMPLE 6 ========================================\n",
            " It\n",
            "======================================== SAMPLE 7 ========================================\n",
            " The\n",
            "======================================== SAMPLE 8 ========================================\n",
            " \n",
            "======================================== SAMPLE 9 ========================================\n",
            " \n",
            "======================================== SAMPLE 10 ========================================\n",
            " \n",
            "================================================================================\n",
            "Model prompt >>> The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started ahead of the 1936 Summer Olympics. After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event.  Q: What was the length of the race?  A: \n",
            "======================================== SAMPLE 1 ========================================\n",
            " Q\n",
            "======================================== SAMPLE 2 ========================================\n",
            " \n",
            "======================================== SAMPLE 3 ========================================\n",
            " The\n",
            "======================================== SAMPLE 4 ========================================\n",
            " \n",
            "======================================== SAMPLE 5 ========================================\n",
            " \n",
            "======================================== SAMPLE 6 ========================================\n",
            " \n",
            "======================================== SAMPLE 7 ========================================\n",
            "\n",
            "\n",
            "======================================== SAMPLE 8 ========================================\n",
            "�\n",
            "======================================== SAMPLE 9 ========================================\n",
            " \n",
            "======================================== SAMPLE 10 ========================================\n",
            " \n",
            "================================================================================\n",
            "Model prompt >>> The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started ahead of the 1936 Summer Olympics. After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event. Q: What was the length of the race? A: 137,000 km Q: Was it larger than previous ones? A: No Q: Where did the race begin? A: Olympia, Greece Q: Where did they go after? A: Athens Q: How many days was the race? A: seven Q: Did they visit any notable landmarks? A: Panathinaiko Stadium Q: And did they climb any mountains? A:\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Mount\n",
            "======================================== SAMPLE 2 ========================================\n",
            " Mount\n",
            "======================================== SAMPLE 3 ========================================\n",
            " Everest\n",
            "======================================== SAMPLE 4 ========================================\n",
            " Everest\n",
            "======================================== SAMPLE 5 ========================================\n",
            " Yes\n",
            "======================================== SAMPLE 6 ========================================\n",
            " Everest\n",
            "======================================== SAMPLE 7 ========================================\n",
            " Everest\n",
            "======================================== SAMPLE 8 ========================================\n",
            " No\n",
            "======================================== SAMPLE 9 ========================================\n",
            " Yes\n",
            "======================================== SAMPLE 10 ========================================\n",
            " Everest\n",
            "================================================================================\n",
            "Model prompt >>> The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started ahead of the 1936 Summer Olympics. After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event.  Q: What was the length of the race?  A: 137,000 km  Q: Was it larger than previous ones?  A: No  Q: Where did the race begin?  A:\n",
            "======================================== SAMPLE 1 ========================================\n",
            " On\n",
            "======================================== SAMPLE 2 ========================================\n",
            " In\n",
            "======================================== SAMPLE 3 ========================================\n",
            " The\n",
            "======================================== SAMPLE 4 ========================================\n",
            " The\n",
            "======================================== SAMPLE 5 ========================================\n",
            " \n",
            "======================================== SAMPLE 6 ========================================\n",
            " China\n",
            "======================================== SAMPLE 7 ========================================\n",
            " In\n",
            "======================================== SAMPLE 8 ========================================\n",
            " In\n",
            "======================================== SAMPLE 9 ========================================\n",
            " In\n",
            "======================================== SAMPLE 10 ========================================\n",
            " It\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5652, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 72, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 90, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 87, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1619, in __exit__\n",
            "    close_thread.join(30.0)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1060, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HO5-IKKbwlk",
        "colab_type": "text"
      },
      "source": [
        "# 3. Summarization\n",
        "\n",
        "Feed in a passage, and add and text TL;DR: or Summary: at the end, and the AI will try to summarise the text.\n",
        "\n",
        "**Example usage**\n",
        "\n",
        "Note the following passage was obtained from a blog post about the mars-water paradox.\n",
        "\n",
        "> !python3 src/interactive_conditional_samples.py --nsamples=3 --length=100 --temperature=1 --model_name='345M'\n",
        ">\n",
        ">Model Prompt >>>\n",
        ">\n",
        ">Mars has been the most extensively studied planet in the Solar System, except of course Earth. For the last 25 years, these missions have focused on the search for life by “following the water.” Although we have acquired compelling evidence of flowing liquid water on early Mars, the fundamental question about how water could be stable under Martian atmospheric conditions remains unsolved. Everything we have learned about Mars points towards a freezing cold Martian climate that would be incapable of stabilizing liquid water throughout Mars’ history.\n",
        "The two ideas that suggest liquid water could not be stable on early Mars are the “Faint Young Sun Paradox” and the Martian orbit. The following is a summary of two recent papers about the problem of Mars’ early climate: “The climate of early Mars,” by Robin Wordsworth, and a book chapter by Robert Haberle and coauthors, “The Early Mars Climate System.” Mars today as we know it is a cold and dry desert with a thin atmosphere not capable of stabilizing liquid water on its surface. However, there is ample evidence that Mars had flowing liquid water on its surface about 4 to 3.7 billion years ago (named as the Noachian Period). The evidence gathered by Mars orbiters, rovers, and landers is geomorphological; (valley networks, crater lakes, purported Northern ocean, glacial landforms, etc.); mineralogical (iron- and magnesium-rich clay minerals, sulfates, chlorides, iron oxides, and oxyhydroxides, etc.); and isotopic (noble gases, nitrogen, hydrogen, oxygen and carbon).\n",
        "TL;DR:\n",
        "Model Prompt >>>\n",
        ">\n",
        ">Theodore McCarrick is the most senior Catholic figure to be dismissed from the priesthood in modern times.\n",
        "US Church officials said allegations he had sexually assaulted a teenager five decades ago were credible.\n",
        "Mr McCarrick, 88, had previously resigned but said he had \"no recollection\" of the alleged abuse.\n",
        "\"No bishop, no matter how influential, is above the law of the Church,\" Cardinal Daniel DiNardo, president of the United States Conference of Catholic Bishops said in a statement.\n",
        "\"For all those McCarrick abused, I pray this judgment will be one small step, among many, toward healing.\"\n",
        "The alleged abuses may have taken place too long ago for criminal charges to be filed because of the statute of limitations.\n",
        "Mr McCarrick was the archbishop of Washington DC from 2001 to 2006. Since his resignation last year from the College of Cardinals, he has been living in seclusion in a monastery in Kansas.\n",
        "He was the first person to resign as a cardinal since 1927.\n",
        "He is among hundreds of members of the clergy accused of sexually abusing children over several decades and his dismissal comes days before the Vatican hosts a summit on preventing child abuse.\n",
        "The Vatican said Pope Francis had ruled Mr McCarrick's expulsion from the clergy as definitive, and would not allow any further appeals against the decision. \n",
        "TL;DR:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGTW_4xCcMCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9f718f5-3312-4da6-a115-57740fdb00ca"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=3 --length=100 --temperature=1 --model_name='345M'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 14:33:51.335853 140626288285568 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:56: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-07-31 14:33:51.337776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-31 14:33:51.340773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.341222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:33:51.341511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:33:51.342917: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:33:51.344166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:33:51.344527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:33:51.346150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:33:51.347806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:33:51.351212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:33:51.351403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.351918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.352344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:33:51.357873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-31 14:33:51.358142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2597480 executing computations on platform Host. Devices:\n",
            "2019-07-31 14:33:51.358180: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-31 14:33:51.419483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.420004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7e27180 executing computations on platform CUDA. Devices:\n",
            "2019-07-31 14:33:51.420047: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-31 14:33:51.420330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.420703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:33:51.420789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:33:51.420836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:33:51.420881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:33:51.420926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:33:51.420965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:33:51.421006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:33:51.421048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:33:51.421189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.421638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.421997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:33:51.422060: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:33:51.423336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-31 14:33:51.423382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-31 14:33:51.423401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-31 14:33:51.423737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.424215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:33:51.424595: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-31 14:33:51.424649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0731 14:33:51.425607 140626288285568 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:57: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 14:33:51.428309 140626288285568 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:59: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0731 14:33:51.428578 140626288285568 deprecation_wrapper.py:119] From /content/gpt-2/src/sample.py:33: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0731 14:33:51.428730 140626288285568 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0731 14:33:57.575561 140626288285568 deprecation.py:323] From /content/gpt-2/src/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0731 14:33:57.577952 140626288285568 deprecation.py:323] From /content/gpt-2/src/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0731 14:34:03.112552 140626288285568 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:67: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0731 14:34:03.436566 140626288285568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> Mars has been the most extensively studied planet in the Solar System, except of course Earth. For the last 25 years, these missions have focused on the search for life by “following the water.” Although we have acquired compelling evidence of flowing liquid water on early Mars, the fundamental question about how water could be stable under Martian atmospheric conditions remains unsolved. Everything we have learned about Mars points towards a freezing cold Martian climate that would be incapable of stabilizing liquid water throughout Mars’ history. The two ideas that suggest liquid water could not be stable on early Mars are the “Faint Young Sun Paradox” and the Martian orbit. The following is a summary of two recent papers about the problem of Mars’ early climate: “The climate of early Mars,” by Robin Wordsworth, and a book chapter by Robert Haberle and coauthors, “The Early Mars Climate System.” Mars today as we know it is a cold and dry desert with a thin atmosphere not capable of stabilizing liquid water on its surface. However, there is ample evidence that Mars had flowing liquid water on its surface about 4 to 3.7 billion years ago (named as the Noachian Period). The evidence gathered by Mars orbiters, rovers, and landers is geomorphological; (valley networks, crater lakes, purported Northern ocean, glacial landforms, etc.); mineralogical (iron- and magnesium-rich clay minerals, sulfates, chlorides, iron oxides, and oxyhydroxides, etc.); and isotopic (noble gases, nitrogen, hydrogen, oxygen and carbon). TL;DR:\n",
            "2019-07-31 14:34:36.922345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            " the accumulation of distinct signatures of more than 80 organic compounds (e.g. ubiquitous traces of nitrogen, O, H, D and K in 70% of Martian sedimentary rocks, silicate minerals, organic carbon, sulfur, and clay minerals) on all three major sample collections on the Pine Meridian (in Tibet) indicates that some other source of water was present on early Mars. According to the \\(\\Objective Looked After\\) considerations, however, there are two striking differences in composition between water\n",
            "======================================== SAMPLE 2 ========================================\n",
            " As a planet, Mars today shows the characteristics of a viridiomatic medium, demonstrating the saperian past of Earth, which presented the basis for water. The present-day planet as we know it existed highly vapid and cold, with an orbit that doesn't indicate a subtle liquid coolant,� meaning Mars wouldn't have been habitable at all. However, even without observations of massive flows on Mars, there has always been evidence of landforms at its surface. We know of abundant\n",
            "======================================== SAMPLE 3 ========================================\n",
            " . . . the evidence suggests the surface conditions of early Mars likely contained a vigorous atmosphere full of chlorinated water so important that a prevailing sea level would have been 50% of the atmosphere width today. Based on theory alone, we can rule out that flow of water could ever be dismissed. Read more... Read more... AFRL Read more .... Professor Jonathan Pipes,‡ alias John Gribben,‡ from Indiana University asks: \"Question raised: What are the chances that beings from\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5652, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 72, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 90, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 87, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1618, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 851, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgrCYpJTdX2w",
        "colab_type": "text"
      },
      "source": [
        "# 4. Translation\n",
        "Provide a few example translations, using the format of english_text = other_language_text, and then english_text = at the end. The AI will try to translate the english text into the other language.\n",
        "\n",
        "**Example usage**\n",
        "\n",
        ">!python3 src/interactive_conditional_samples.py --nsamples=3 --temperature=1 --model_name='345M'\n",
        ">\n",
        ">Model Prompt >>>\n",
        ">\n",
        ">Good morning. = Buenos días.\n",
        "I am lost. Where is the restroom? = Estoy perdido. ¿Dónde está el baño?\n",
        "How much does it cost? = ¿Cuánto cuesta?\n",
        "How do you say maybe in Spanish? = ¿Cómo se dice maybe en Español?\n",
        "Would you speak slower, please. = Por favor, habla mas despacio.\n",
        "Where is the book store? = ¿Dónde está la librería?\n",
        "At last a feminist comedian who makes jokes about men. = Por fin un cómico feminista que hace chistes sobre hombres.\n",
        "How old are you? =\n",
        "Try it out yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEN35VE9dm97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9205ff07-cd5a-4a4b-d3ff-ad04cab7aa10"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --nsamples=3 --temperature=1 --model_name='345M'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 14:37:21.173357 139647590905728 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:56: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-07-31 14:37:21.175250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-31 14:37:21.178265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.178668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:37:21.178975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:37:21.180349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:37:21.181658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:37:21.182057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:37:21.183672: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:37:21.185143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:37:21.188620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:37:21.188818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.189340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.189697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:37:21.195212: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-31 14:37:21.195512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f5b480 executing computations on platform Host. Devices:\n",
            "2019-07-31 14:37:21.195551: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-31 14:37:21.258828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.259528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x87e9180 executing computations on platform CUDA. Devices:\n",
            "2019-07-31 14:37:21.259569: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-31 14:37:21.259843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.260236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-31 14:37:21.260310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:37:21.260352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-31 14:37:21.260394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-31 14:37:21.260436: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-31 14:37:21.260481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-31 14:37:21.260517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-31 14:37:21.260554: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-31 14:37:21.260677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.261154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.261510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-31 14:37:21.261583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-31 14:37:21.262807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-31 14:37:21.262842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-31 14:37:21.262871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-31 14:37:21.263230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.263688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-31 14:37:21.264083: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-31 14:37:21.264143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0731 14:37:21.265128 139647590905728 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:57: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 14:37:21.267793 139647590905728 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:59: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0731 14:37:21.268066 139647590905728 deprecation_wrapper.py:119] From /content/gpt-2/src/sample.py:33: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0731 14:37:21.268221 139647590905728 deprecation_wrapper.py:119] From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0731 14:37:27.360104 139647590905728 deprecation.py:323] From /content/gpt-2/src/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0731 14:37:27.362765 139647590905728 deprecation.py:323] From /content/gpt-2/src/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0731 14:37:32.693824 139647590905728 deprecation_wrapper.py:119] From src/interactive_conditional_samples.py:67: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0731 14:37:32.996291 139647590905728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> Good morning. = Buenos días. I am lost. Where is the restroom? = Estoy perdido. ¿Dónde está el baño? How much does it cost? = ¿Cuánto cuesta? How do you say maybe in Spanish? = ¿Cómo se dice maybe en Español? Would you speak slower, please. = Por favor, habla mas despacio. Where is the book store? = ¿Dónde está la librería? At last a feminist comedian who makes jokes about men. = Por fin un cómico feminista que hace chistes sobre hombres. How old are you? =\n",
            "2019-07-31 14:37:54.526445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            " ¿Qué? How do you think men will respond? = ¿Bon? Would you like to meet her? = ¿Bueno? Cookies and milk for the cake? = ¿Cómo sobradas por favor? How many credits do you have? = ¿Qué?\n",
            "Quantiò es uno (planned interruption); Ciudad de presidente nínfyinga que se ha día iregresar este salto día ?????? (Though it was planned to cut my leisure, but it was postponed, finally, it was postponed; he did not even loved me brotherly. He did not even want anything, I mean to love him -- whatever he wanted to.)\n",
            "Cerrarse est lado marks de 0 x 20 = 0.88 very generic --------------------------------------------------------------------------- value la conference Nº 101ba Vita for fruits prostitulates desrots Quadriton ????????직 어요, 테문로 않았, 테문의 제꿐를 인안 방송트 최사추터에 생적 았마으면상, 되어 중т 뫁 교현, 몽현 만들어요 매영, 몽현 만들어요 = New numerical system for scientific information was used.\n",
            "Centro de financialidad permitir nos estan ciferencia gratis = Supply back a bundle of custom accounting permits with general exhilaration.\n",
            "Central del salento denunci Arias del Speranza. An airplane reckons = Omarició Español un reunió detección perpetuales de una CaptainOC notícias del salento derorisió con mis Bautista niebla definición del grupo ligamente del fuerte : Secret of page 22.1633 =...stripped ... leaving him with no opportunity to escape from the coast\n",
            "Democracy\n",
            "New men into the Republic. - Omsk will rise up of its own will BE\n",
            "======================================== SAMPLE 2 ========================================\n",
            " César si manegüenza hondo valores. How old were you before sex? = Presendez especial que hejánte modo humano. What power do you currently feel? = Placeras en La Cartamessa Lois Sandoval Lewis told McElroy she did social criticism as a result of her studies at Taverne University before going onto graduate school with Friedman at Columbia University. She began teaching in 2008 and in 2010 graduated from Mishchenko Public School in Haiti where she taught under Monica Hickman. Lewis interviewed for a foreign language assignment for a Spanish news website. Lewis did considerably better in the interviews than she did in the interview itself, and a significant percentage of the survey respondents thought she answered questions too quickly for her place in the interview. She is considered a social commentator for her well-written and persuasive reports, which are chosen by the students for best/worst interviews, and reactions to them have been broadly positive. Monthly acknowledges she has a magazine subscription signup system and a book deal with Village Voice and SK SK Israeli Israeli blogger who has many Twitter followers along her academic credits. Similarly, NYU journalism professor Michael Flynn told a group of college students that the essay units they write and put up support students, who promote their own graduate studies at NYU. General Purpose Communications director Carl Marchetti in his capacity as editor of Within Tolerance magazine points to multiple letters in an over-circulated Jubilee concerns contest from PLO writers to read at the University as evidence that student activism helps create relevance to Israeli students. Mrs. Shroy said that she was most distressed by thoughtful Israeli critics in academic nonrepresentation. They are pushed aside by their counterparts in academic missions who are Israeli if impoverished or fail to consolidate the close links between America's academic establishment and the academic community that is controlled by liberal Jewish organizations like the Jewish Federations. Some pro-Palestinian outfits even do this to Israeli progressives -- noting that being married in America would prevent you from studying any theology class around here. Hubert Velez only for one year at NYU yet, he has read four \"Best and Worst Authors of 2009\" lists. These lists appear on a kosher site and Huang used to carry them with him when he was there as well to demonstrate his solidarity to many students of color in his neighborhood. Bringing up language skills knocks Voltaire out of Syrian eyes English is Chomsky's largest home language and his chessbooks helped understand further into French whose texts he completed both master's titles. Bill Sikes for his rather watch\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}